{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-20T05:28:49.625792200Z",
     "start_time": "2024-03-20T05:28:49.612998100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Implement Layers of a Nueral Net by hand\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "def get_absolute_directory_path(folder_name):\n",
    "    current_dir = os.path.abspath(__file__)\n",
    "    while not os.path.exists(os.path.join(current_dir, folder_name)):\n",
    "        current_dir = os.path.dirname(current_dir)\n",
    "    return os.path.join(current_dir, folder_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T05:28:51.345694700Z",
     "start_time": "2024-03-20T05:28:51.341741400Z"
    }
   },
   "id": "395d60330928cecf"
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "dataset = open('../names.txt', 'r').read().splitlines()\n",
    "chars = sorted(list(set(''.join(dataset))))\n",
    "index_lookup_table = {index + 1: char for index, char in enumerate(chars)}\n",
    "index_lookup_table[0] = '.'\n",
    "\n",
    "# index_lookup_table"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T07:03:51.465577800Z",
     "start_time": "2024-03-20T07:03:51.451524100Z"
    }
   },
   "id": "ac871492cc5a8333"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "xenc = torch.nn.functional.one_hot(torch.tensor([0]), num_classes=27).float()\n",
    "elems = xenc.clone().detach()\n",
    "print(elems)\n",
    "# plt.plot(elems)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T05:34:46.584726700Z",
     "start_time": "2024-03-20T05:34:46.518603800Z"
    }
   },
   "id": "4b2465c48b563bef"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "'yofvwqjkdktcnblz.'"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "# completely untrained\n",
    "def nueral_net_algorithm(\n",
    "        seed_generator, \n",
    "        num_of_obj_classes, \n",
    "        W, \n",
    "        lookup_table\n",
    "):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        # forward pass\n",
    "        xenc = torch.nn.functional.one_hot(torch.tensor([ix]), num_classes=num_of_obj_classes).float()\n",
    "        # used to predict log counts , why does tensor multiplication automatically return log count?\n",
    "        logits = xenc @ W\n",
    "        # manual softmax function (make nueral net from probs),  e^z_i / from j->k sum(e^z_j) aka 'normalization function'\n",
    "        counts = logits.exp()  # equivalent to N matrix in counting bigram or P matrix in normalized matrix of probabilities based on count\n",
    "        p = counts / counts.sum(1, keepdims=True)  # 1 doesn't work, but -1 does? why? \n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=seed_generator).item()\n",
    "        out.append(lookup_table[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    return ''.join(out)\n",
    "\n",
    "# Sample NueroNet\n",
    "nueral_net_algorithm(g, 27, torch.randn((27, 27), generator=g, requires_grad=True), index_lookup_table)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T07:01:16.059050100Z",
     "start_time": "2024-03-20T07:01:16.050688500Z"
    }
   },
   "id": "9782717dbee3607e"
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "# invert atoi into i2c\n",
    "ctoi = {c: ix+1 for ix, c in enumerate(chars)}\n",
    "itoc = {ix:c for c, ix in ctoi.items()}\n",
    "itoc[0]='.'\n",
    "ctoi[\".\"]=0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T07:32:56.438049300Z",
     "start_time": "2024-03-20T07:32:56.401524Z"
    }
   },
   "id": "ba743e76c0252fe"
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... -----> e\n",
      "..e -----> m\n",
      ".em -----> m\n",
      "emm -----> a\n",
      "mma -----> .\n"
     ]
    }
   ],
   "source": [
    "blocksize = 3 \n",
    "# X is input, \n",
    "# Y is the output. in test Y is the expected value\n",
    "X,Y = [], []\n",
    "for word in dataset[:1]:\n",
    "    print(word)\n",
    "    context = [0] * blocksize # A zero vector\n",
    "    for ch in word + '.':\n",
    "        ix = ctoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix) # the solution in space. \n",
    "        print(\n",
    "            ''.join(itoc[i] for i in context),\n",
    "            '----->',\n",
    "            itoc[ix]\n",
    "        )\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T17:42:25.143387500Z",
     "start_time": "2024-03-20T17:42:25.123978900Z"
    }
   },
   "id": "9738d7d4ceaacd79"
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  5],\n",
      "        [ 0,  5, 13],\n",
      "        [ 5, 13, 13],\n",
      "        [13, 13,  1]])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T18:20:54.542024300Z",
     "start_time": "2024-03-20T18:20:54.501750Z"
    }
   },
   "id": "3aa5f699dda40764"
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5, 13, 13,  1,  0])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "print(Y)\n",
    "print(Y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T18:21:08.047680200Z",
     "start_time": "2024-03-20T18:21:08.004776400Z"
    }
   },
   "id": "30e7a59e6d28d11c"
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3]): torch.int64 torch.Size([5]): torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X.shape}: {X.dtype}\", f\"{Y.shape}: { Y.dtype}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T17:42:30.386502900Z",
     "start_time": "2024-03-20T17:42:30.368929800Z"
    }
   },
   "id": "cb387b0812739408"
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [],
   "source": [
    "C = torch.randn((27,2)) # embedding\n",
    "# C\n",
    "# C.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T17:54:25.363914200Z",
     "start_time": "2024-03-20T17:54:25.300632600Z"
    }
   },
   "id": "324dd85238dd137a"
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[[ 0.3766,  0.8133],\n         [ 0.3766,  0.8133],\n         [ 0.3766,  0.8133]],\n\n        [[ 0.3766,  0.8133],\n         [ 0.3766,  0.8133],\n         [ 0.3327, -1.6047]],\n\n        [[ 0.3766,  0.8133],\n         [ 0.3327, -1.6047],\n         [-0.0398, -0.5801]],\n\n        [[ 0.3327, -1.6047],\n         [-0.0398, -0.5801],\n         [-0.0398, -0.5801]],\n\n        [[-0.0398, -0.5801],\n         [-0.0398, -0.5801],\n         [ 0.2930, -0.2716]]])"
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "print(emb.shape)\n",
    "emb\n",
    "# torch.nn.functional.one_hot(torch.tensor(5),num_classes=27).float() @ C"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T18:20:17.763593Z",
     "start_time": "2024-03-20T18:20:17.695844Z"
    }
   },
   "id": "6a1e3763ec897b7b"
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1817e+00, -1.9138e+00,  5.5493e+00, -1.2683e+00,  8.6979e-02,\n",
      "         -1.1546e+00, -3.2126e-02,  1.9304e+00,  9.8445e-01, -5.6624e+00,\n",
      "         -4.6631e+00, -1.6535e+00,  1.2791e-01, -1.9631e-01, -1.3475e+01,\n",
      "         -1.0500e+00, -2.4372e+00, -5.1074e-01,  2.2103e-01,  2.4169e-01,\n",
      "          1.1571e+00,  6.3173e-01,  3.0266e+01,  4.1182e+00, -6.4970e-01,\n",
      "         -3.9281e+00, -2.0625e+00, -1.1188e+00, -5.9488e-01,  4.1467e-01,\n",
      "         -1.3135e+00, -1.1390e+00,  4.2340e-01,  6.5654e-01, -4.7994e+00,\n",
      "         -2.7832e-02, -4.0230e-01,  9.5865e-01, -1.0010e+00,  4.3827e-02,\n",
      "          2.9399e-01,  3.0620e+00,  2.0305e-01, -3.6356e-01,  6.0252e-01,\n",
      "          3.4954e-01, -1.6969e+00, -3.8861e-01,  3.0887e+00,  2.4025e+00,\n",
      "          2.0700e+00,  5.8174e-01,  5.4589e+00, -1.1988e+01, -8.1238e+00,\n",
      "          7.9179e-01,  1.6649e+00, -6.7288e+01,  3.0885e-01, -7.0528e-01,\n",
      "         -4.6119e+01, -3.2396e-01,  7.0800e-02,  1.5717e+00, -8.8467e-01,\n",
      "          2.2254e-01,  2.2337e+00, -5.1579e-01, -4.1079e-02, -1.7545e+00,\n",
      "          8.0536e-01, -4.3990e-01, -1.8765e+00,  3.5165e+00,  5.2831e-02,\n",
      "         -8.0674e-01, -4.2393e+00,  1.2613e+00, -9.1374e+00, -2.6266e+00,\n",
      "         -1.3774e-01,  1.9950e+00, -3.9331e-01,  2.2279e-01,  1.5840e+00,\n",
      "          3.5751e-01,  1.0486e-01,  4.4058e-01,  3.4648e-01,  2.9672e-01,\n",
      "         -2.2135e+00,  1.7756e-01, -3.2538e-01,  7.4449e+00, -8.1177e-01,\n",
      "         -1.8465e-02, -2.5374e-01,  2.6504e+01, -1.0232e-01,  5.4645e-01],\n",
      "        [-3.9850e-01, -2.1355e-01,  1.5359e+01, -8.1753e+00, -2.3898e-01,\n",
      "          1.6243e+01,  1.3907e+00, -5.4538e-01, -2.2781e+01,  1.0531e+00,\n",
      "          4.7117e+00, -4.8788e+00, -1.5716e+00, -2.3299e-03,  2.1478e+00,\n",
      "         -1.1737e+00, -6.0314e+01,  1.8190e+00, -1.8455e-01, -9.8773e-02,\n",
      "         -6.9428e-02, -3.4391e-01,  3.1691e+00, -6.4700e-01,  2.6182e+00,\n",
      "         -3.2865e-01, -5.9284e-01,  4.9970e+00, -1.4125e+00,  3.1087e-01,\n",
      "         -5.6088e-01, -2.1408e+00, -3.7012e+00, -1.0515e+01,  5.9107e+00,\n",
      "         -1.3228e-01,  6.5549e-01,  9.3944e-02, -1.0753e+00, -8.1191e-01,\n",
      "         -1.0895e+00, -1.3951e+01, -1.9716e+00, -1.3352e-01, -2.7345e+00,\n",
      "          3.2944e-01, -5.7714e-01, -2.4974e-01, -4.6987e-02, -3.0375e-01,\n",
      "         -4.8976e+00, -5.9292e-01, -3.4329e+00, -2.1284e+00, -2.8674e+00,\n",
      "          3.6070e+00,  9.3156e+00,  8.8376e-02,  1.0111e+00,  3.8920e-02,\n",
      "          6.2454e-01,  3.6774e+00, -3.9016e-02,  6.4699e-01,  3.2931e-01,\n",
      "         -6.0334e+00, -6.2597e-01, -2.8460e+00, -1.3313e+00,  1.7482e+00,\n",
      "         -1.2805e+00, -3.1558e-01, -2.2713e-01,  1.9271e+00, -4.9974e+00,\n",
      "         -7.9572e-01, -9.1306e-01,  1.0986e+01,  2.1752e-02,  9.2575e-01,\n",
      "         -2.5553e-01,  3.0657e-01, -8.6168e-01, -5.1161e-01,  1.3608e+01,\n",
      "         -2.5950e+00,  2.7424e-01,  3.8666e-01, -5.1977e+00, -1.7559e-01,\n",
      "          3.8863e+00, -7.5345e-02,  8.5959e-01, -7.6973e-01,  5.0476e-01,\n",
      "          2.2597e+00, -1.3971e+00,  1.1998e+00, -2.4088e-01,  8.7439e-01],\n",
      "        [ 7.3444e-01, -1.0390e+00, -5.5782e-01,  1.3051e-01, -7.1015e-01,\n",
      "         -3.0503e+01,  2.2995e+00, -6.2901e-02, -1.8953e+00,  2.3176e+00,\n",
      "          2.3579e-01, -2.9362e-01, -2.6672e+00, -6.5613e+00,  2.7284e-01,\n",
      "          4.1332e+00, -5.9400e-01, -3.7441e-01,  6.3577e+00,  2.1562e+00,\n",
      "          8.3499e-02,  7.5231e-01,  1.4199e+01,  7.1435e-03,  4.1811e-01,\n",
      "          1.6032e+00, -1.2354e+00, -2.7164e-01,  9.2673e-01, -1.0663e+00,\n",
      "         -3.7742e-01, -7.0326e-01,  1.1006e+00,  1.2290e-01,  1.7109e-02,\n",
      "          9.3125e-02,  1.7739e+00,  2.1293e+00, -3.5475e+00, -1.2060e+00,\n",
      "          2.4238e+00,  1.3668e-01, -6.2221e-02, -8.9379e-01,  2.0668e+00,\n",
      "          1.4627e-01,  3.3989e-01, -2.5272e-01,  1.4695e+00,  1.3717e+00,\n",
      "          1.8087e+00,  7.1890e-01, -3.7262e+00, -6.0796e-01,  3.6611e+00,\n",
      "          3.1479e-01, -6.1699e-01, -4.7675e-01,  3.1688e-02,  2.1409e+01,\n",
      "         -2.0582e+00,  9.9531e-01,  3.2200e+00, -3.4298e-01, -3.2995e+00,\n",
      "          1.9497e+00, -4.0604e-01, -3.5628e-01,  1.2343e+00, -1.5858e-01,\n",
      "          9.2696e-01,  4.1127e-01, -2.6483e+00,  1.3170e-01,  8.4850e-01,\n",
      "          1.4092e-01,  2.2327e+00, -4.9449e-01,  4.7079e-01,  9.0959e-01,\n",
      "          1.1471e+01,  7.4437e+00,  6.2468e-02,  1.2342e+00,  3.6064e-01,\n",
      "         -1.4642e-01, -4.6737e+00,  4.9522e-02,  1.3697e+00, -2.6861e+00,\n",
      "         -3.9700e-01, -2.3464e+00, -1.4101e+00,  3.2676e-01,  2.2818e+00,\n",
      "         -2.0055e+00, -3.0475e-01, -2.4810e+00, -4.4759e-01, -3.5391e+00],\n",
      "        [ 2.2364e+00,  2.5405e+00,  9.1925e-01,  1.5139e+00,  1.8899e+00,\n",
      "         -5.2223e-01, -1.3421e+00,  8.0739e+00,  7.9493e-01, -2.3079e+00,\n",
      "         -6.1826e-02, -2.2502e+00, -4.6981e+00,  8.9424e-01, -1.5821e+00,\n",
      "         -9.3598e-01, -1.9225e+00, -9.6299e-01,  1.3711e+00, -1.2670e+00,\n",
      "         -5.4667e-01,  1.3981e+00, -7.7460e+01, -6.0389e-01, -2.5532e-01,\n",
      "          1.9333e+00, -3.0941e+00,  1.1771e+01,  4.1043e+00,  2.7196e-01,\n",
      "         -9.7527e-01,  2.9704e-01,  1.5867e-01,  2.8122e-01, -1.3419e+00,\n",
      "         -2.7907e+00, -2.9194e+01,  2.4556e-01,  5.9102e-01,  2.6653e+00,\n",
      "          3.7378e-01,  1.4398e+00,  1.2928e+00,  3.9940e-01, -9.5851e-01,\n",
      "         -3.0069e+00, -3.8715e+00,  2.4434e+00, -2.9723e+00, -7.3770e+00,\n",
      "          2.3717e+00,  3.1267e-01, -2.3835e-01,  8.5760e-01, -2.1136e+00,\n",
      "         -2.8748e-01,  1.1008e+00, -1.4287e+01,  1.8148e-01, -5.2803e-01,\n",
      "          1.1734e+00,  3.7267e-01, -2.5777e-01, -4.1081e+00, -1.2156e+00,\n",
      "         -7.1187e+00, -1.3305e+00, -2.0684e-01, -2.7856e-01, -6.5425e+00,\n",
      "          1.3485e+00,  2.4734e+00, -2.0126e+01, -3.3811e-01,  1.4552e+00,\n",
      "          1.7645e+00,  1.0377e+00, -1.2428e+00,  3.1129e-01,  2.1107e-01,\n",
      "          6.7302e-01, -1.3905e-03, -2.6829e+00, -7.6074e-01, -7.8766e-01,\n",
      "          1.0870e+01, -8.7906e-01,  2.1462e-02,  1.2082e+00,  2.9447e+00,\n",
      "          1.8149e+00,  2.0494e+00,  2.4583e+00, -8.0816e-01,  1.5716e-01,\n",
      "          9.9817e+00, -6.9058e-01, -7.1537e+00,  5.0154e-01,  7.0943e-01],\n",
      "        [-8.1858e+00, -1.7070e+01,  1.3342e+00,  7.1353e+00,  1.0492e-01,\n",
      "         -2.1610e+00, -1.6638e+00,  4.0838e-02, -9.8301e-01, -1.6701e+00,\n",
      "         -3.8374e+01, -3.1501e+00, -1.4162e-01,  2.3959e+00,  6.4073e-01,\n",
      "          5.3913e-01,  5.9049e-01,  8.4527e-01,  7.1512e-01,  5.3702e-01,\n",
      "         -2.3529e-01,  2.8280e-01,  2.9009e+00,  1.7440e-01,  1.1730e-01,\n",
      "          3.6109e+00,  7.7588e-02, -3.2233e-01, -2.8790e+00, -8.8498e-01,\n",
      "         -2.7450e+00,  5.4382e-01, -1.9130e-01,  4.0765e+00, -2.0357e+00,\n",
      "          3.6836e+00,  1.0873e+00,  2.0004e+00,  3.9095e+00,  1.2393e-01,\n",
      "         -4.8111e-01,  9.5212e-01, -1.5905e+00,  6.4524e-01,  4.7016e+00,\n",
      "         -7.4208e+00,  5.2868e+00, -8.6784e-01, -4.5436e+00, -1.5377e+00,\n",
      "          6.3603e+00, -4.1898e+00,  1.9391e-02,  2.2055e+00,  6.5572e+00,\n",
      "          6.3158e+00, -2.1280e+00, -6.4559e+01,  4.6569e-01,  2.2166e-01,\n",
      "          7.4819e-01, -4.4911e-01, -1.2912e+00,  7.0536e-01, -3.5751e-01,\n",
      "         -1.0274e+00, -1.2391e+00, -2.8881e-01,  3.3590e-01, -5.1971e-02,\n",
      "          9.3044e-01, -5.4289e-01, -1.2635e+00, -7.5521e-01, -2.7926e-01,\n",
      "          2.8282e+00,  5.7319e-01, -1.4140e-01, -7.5406e-01,  8.0441e-03,\n",
      "         -8.6441e-01,  8.3335e-01, -5.0614e-02,  8.4549e+00,  4.5660e+00,\n",
      "          9.2381e-01,  9.7753e-01, -7.7446e-01, -2.6311e-01,  1.9842e+00,\n",
      "         -2.3095e+00, -1.1980e-01,  3.3282e+01,  5.9842e-02,  7.2348e-01,\n",
      "         -8.9985e-01,  3.2085e+00, -1.0160e+00,  1.2939e+00,  2.9316e+00]])\n",
      "torch.Size([5, 100])\n"
     ]
    }
   ],
   "source": [
    "# x = 3*2, because 3 wrds each for the 2d embedding\n",
    "# y = any number of nuerons\n",
    "W1 = torch.randn((6,100)) \n",
    "\n",
    "# biases\n",
    "b1 = torch.randn(100)\n",
    "\n",
    "# torch.cat([emb[:,0,:], emb[:,1,:], emb[:,2,:]],1) # wont scale\n",
    "\n",
    "# scales better when inputs>3 or n inputs\n",
    "# torch.cat(torch.unbind(emb,1),1)\n",
    "\n",
    "# hidden layer 1\n",
    "# (emb @ W1) + b1 # cant multiply 15x2 by 6x100\n",
    "# hlyr1_v = emb.view(5,6) @ W1 + b1 # cast emb to 5,6 by\n",
    "hlyr1_v = emb.view(-1,6) @ W1 + b1 # cast emb to 5,6 by\n",
    "\n",
    "h = torch.tan(hlyr1_v)\n",
    "print(h)\n",
    "print(h.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T18:35:28.226088600Z",
     "start_time": "2024-03-20T18:35:28.183539300Z"
    }
   },
   "id": "425a559f32619fd2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
